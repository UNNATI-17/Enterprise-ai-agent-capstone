{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T19:32:59.171078Z","iopub.execute_input":"2025-11-30T19:32:59.172050Z","iopub.status.idle":"2025-11-30T19:32:59.704207Z","shell.execute_reply.started":"2025-11-30T19:32:59.172016Z","shell.execute_reply":"2025-11-30T19:32:59.703352Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"!pip install -q google-generativeai python-dotenv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:10:24.263489Z","iopub.execute_input":"2025-12-01T06:10:24.263847Z","iopub.status.idle":"2025-12-01T06:10:28.350720Z","shell.execute_reply.started":"2025-12-01T06:10:24.263816Z","shell.execute_reply":"2025-12-01T06:10:28.349502Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install -U google-generativeai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:10:16.201238Z","iopub.execute_input":"2025-12-01T06:10:16.201580Z","iopub.status.idle":"2025-12-01T06:10:20.448890Z","shell.execute_reply.started":"2025-12-01T06:10:16.201555Z","shell.execute_reply":"2025-12-01T06:10:20.447831Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.28.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.12.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.15.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.5)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.2)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import google.generativeai as genai\nimport os\nfrom dotenv import load_dotenv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:10:11.035188Z","iopub.execute_input":"2025-12-01T06:10:11.035929Z","iopub.status.idle":"2025-12-01T06:10:11.040363Z","shell.execute_reply.started":"2025-12-01T06:10:11.035899Z","shell.execute_reply":"2025-12-01T06:10:11.039414Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"GOOGLE_API_KEY=\"GOOGLE_API_KEY\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:10:51.978772Z","iopub.execute_input":"2025-12-01T06:10:51.979158Z","iopub.status.idle":"2025-12-01T06:10:51.984198Z","shell.execute_reply.started":"2025-12-01T06:10:51.979121Z","shell.execute_reply":"2025-12-01T06:10:51.983220Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Load Google API key\nfrom kaggle_secrets import UserSecretsClient\nimport google.generativeai as genai\n\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\nif not GOOGLE_API_KEY:\n    raise ValueError(\"Google API Key not found in Kaggle Secrets.\")\n\nprint(\"‚úÖ Google API Key loaded successfully.\")\n\n# Correct configuration\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# Correct model initialization\nmodel = genai.GenerativeModel(\"gemini-2.5-flash\")\n\n# Correct API call\nresponse = model.generate_content(\"Hello! Can you summarize this?\")\n\n# Print output\nprint(\"‚úÖ Gemini test successful!\")\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:10:56.008495Z","iopub.execute_input":"2025-12-01T06:10:56.008846Z","iopub.status.idle":"2025-12-01T06:10:59.373845Z","shell.execute_reply.started":"2025-12-01T06:10:56.008822Z","shell.execute_reply":"2025-12-01T06:10:59.372967Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Google API Key loaded successfully.\n‚úÖ Gemini test successful!\nHello there!\n\nAbsolutely, I can summarize something for you.\n\nHowever, it looks like you haven't provided the text yet.\n\nPlease paste or type the content you'd like me to summarize, and I'll be happy to help!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Step 3: Test request\nmodel = genai.GenerativeModel(\"gemini-2.5-flash\")\n\nresponse = model.generate_content(\"Hello! Can you summarize this?\")\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:11:02.694688Z","iopub.execute_input":"2025-12-01T06:11:02.695437Z","iopub.status.idle":"2025-12-01T06:11:05.512435Z","shell.execute_reply.started":"2025-12-01T06:11:02.695409Z","shell.execute_reply":"2025-12-01T06:11:05.511350Z"}},"outputs":[{"name":"stdout","text":"Hello!\n\nYes, I can definitely summarize something for you!\n\nHowever, it seems you forgot to provide the text, article, document, or whatever it is you'd like me to summarize.\n\nPlease paste or type the text here, provide a link, or upload the file, and I'll be happy to give you a concise summary!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Step 4: Define system instructions and run a structured query\n\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.5-flash\",\n    system_instruction=(\n        \"You are an Enterprise Demo Agent. \"\n        \"Your job is to answer user questions clearly and concisely.\"\n    )\n)\n\nquery = \"Explain what an Enterprise AI Agent is in simple words.\"\n\nresponse = model.generate_content(query)\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:11:09.291276Z","iopub.execute_input":"2025-12-01T06:11:09.292172Z","iopub.status.idle":"2025-12-01T06:11:11.370324Z","shell.execute_reply.started":"2025-12-01T06:11:09.292140Z","shell.execute_reply":"2025-12-01T06:11:11.369330Z"}},"outputs":[{"name":"stdout","text":"An Enterprise AI Agent is a smart software program that uses Artificial Intelligence to perform specific tasks or make decisions for a business.\n\nThink of it as a specialized, automated assistant that helps companies streamline operations, answer questions, or handle routine work more efficiently.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# STEP 5 ‚Äî Gemini Tool Calling (Complete Working Code for Kaggle)\n\nimport json\nimport google.generativeai as genai\n\n# 1. Define the tool schema (JSON schema, not Python functions)\ntools = [\n    {\n        \"function_declarations\": [\n            {\n                \"name\": \"get_employee_details\",\n                \"description\": \"Fetch role and experience of an employee.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"name\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"name\"]\n                }\n            }\n        ]\n    }\n]\n\n# 2. Mock Python function ‚Äî executed manually after Gemini calls the tool\ndef get_employee_details(name: str):\n    employee_db = {\n        \"Unnati\": {\"role\": \"Frontend Developer\", \"experience\": \"2 years\"},\n        \"Priyanka\": {\"role\": \"Team Lead\", \"experience\": \"5 years\"},\n        \"Bhoomi\": {\"role\": \"Backend Developer\", \"experience\": \"3 years\"}\n    }\n    return employee_db.get(name, {\"error\": \"Employee not found\"})\n\n\n# 3. Build model with tool schema\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.5-flash\",\n    tools=tools\n)\n\n# 4. Trigger tool call\nresponse = model.generate_content(\"Get details for employee Unnati\")\n\nprint(\"RAW RESPONSE:\\n\", response)\n\n# 5. Extract tool call arguments (Kaggle-safe version)\nparts = response.candidates[0].content.parts\n\nif hasattr(parts[0], \"function_call\") and parts[0].function_call:\n    call = parts[0].function_call\n    args = dict(call.args)  # convert MapComposite to normal dict\n\n    print(\"\\nFunction call detected:\")\n    print(\"Name:\", call.name)\n    print(\"Args:\", args)\n\n    # Execute our mock tool\n    result = get_employee_details(args[\"name\"])\n\n    print(\"\\nTool Execution Result:\", result)\nelse:\n    print(\"No tool call detected.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:11:14.827893Z","iopub.execute_input":"2025-12-01T06:11:14.828637Z","iopub.status.idle":"2025-12-01T06:11:15.485667Z","shell.execute_reply.started":"2025-12-01T06:11:14.828609Z","shell.execute_reply":"2025-12-01T06:11:15.484924Z"}},"outputs":[{"name":"stdout","text":"RAW RESPONSE:\n response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"parts\": [\n              {\n                \"function_call\": {\n                  \"name\": \"get_employee_details\",\n                  \"args\": {\n                    \"name\": \"Unnati\"\n                  }\n                }\n              }\n            ],\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"STOP\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 49,\n        \"candidates_token_count\": 18,\n        \"total_token_count\": 133\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)\n\nFunction call detected:\nName: get_employee_details\nArgs: {'name': 'Unnati'}\n\nTool Execution Result: {'role': 'Frontend Developer', 'experience': '2 years'}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# STEP 6 ‚Äî Full Automatic Agent Loop (FIXED)\n\nimport google.generativeai as genai\nimport json\n\n# ---- 1. Tool Schema ----\ntools = [\n    {\n        \"function_declarations\": [\n            {\n                \"name\": \"get_employee_details\",\n                \"description\": \"Fetch role and experience of an employee.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"name\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"name\"]\n                }\n            }\n        ]\n    }\n]\n\n# ---- 2. Actual Python function ----\ndef get_employee_details(name: str):\n    database = {\n        \"Unnati\": {\"role\": \"Frontend Developer\", \"experience\": \"2 years\"},\n        \"Priyanka\": {\"role\": \"Team Lead\", \"experience\": \"5 years\"},\n        \"Bhoomi\": {\"role\": \"Backend Developer\", \"experience\": \"3 years\"},\n    }\n    return database.get(name, {\"error\": \"Employee not found\"})\n\n\n# ---- 3. Initialize Model ----\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.5-flash\",\n    tools=tools\n)\n\n\n# ---- 4. Agent Loop ----\ndef agent_loop(user_input):\n    print(f\"\\nUSER: {user_input}\")\n\n    # Phase 1 ‚Äî User ‚Üí Gemini\n    response = model.generate_content(user_input)\n    parts = response.candidates[0].content.parts\n\n    # Phase 2 ‚Äî Tool call?\n    if hasattr(parts[0], \"function_call\") and parts[0].function_call:\n        call = parts[0].function_call\n        args = dict(call.args)\n\n        print(\"\\nüîß Gemini requested tool:\", call.name)\n        print(\"Arguments:\", args)\n\n        # Run the Python tool\n        result = get_employee_details(args[\"name\"])\n        print(\"\\nüõ† Tool Result:\", result)\n\n        # Phase 3 ‚Äî Return result back to Gemini\n        final_response = model.generate_content(\n            [\n                {\"role\": \"user\", \"parts\": user_input},\n                {\n                    \"role\": \"tool\",\n                    \"parts\": [\n                        {\n                            \"function_response\": {\n                                \"name\": call.name,\n                                \"response\": result   # FIXED: dict, not string\n                            }\n                        }\n                    ]\n                }\n            ]\n        )\n\n        print(\"\\nü§ñ AGENT RESPONSE:\")\n        print(final_response.text)\n\n    else:\n        print(\"\\nü§ñ AGENT RESPONSE:\")\n        print(parts[0].text)\n\n\n# ---- 5. Test it ----\nagent_loop(\"Get details for employee Unnati\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:12:07.218389Z","iopub.execute_input":"2025-12-01T06:12:07.218725Z","iopub.status.idle":"2025-12-01T06:12:08.470375Z","shell.execute_reply.started":"2025-12-01T06:12:07.218696Z","shell.execute_reply":"2025-12-01T06:12:08.469207Z"}},"outputs":[{"name":"stdout","text":"\nUSER: Get details for employee Unnati\n\nüîß Gemini requested tool: get_employee_details\nArguments: {'name': 'Unnati'}\n\nüõ† Tool Result: {'role': 'Frontend Developer', 'experience': '2 years'}\n\nü§ñ AGENT RESPONSE:\nUnnati is a Frontend Developer with 2 years of experience.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# STEP 7 ‚Äî Add multiple tools + Universal agent\n\nimport google.generativeai as genai\nimport json\n\n# ---- 1. Define All Tools ----\ntools = [\n    {\n        \"function_declarations\": [\n            {\n                \"name\": \"get_employee_details\",\n                \"description\": \"Fetch role and experience of an employee.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\"name\": {\"type\": \"string\"}},\n                    \"required\": [\"name\"]\n                }\n            },\n            {\n                \"name\": \"get_salary_details\",\n                \"description\": \"Get salary breakdown for an employee.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\"name\": {\"type\": \"string\"}},\n                    \"required\": [\"name\"]\n                }\n            },\n            {\n                \"name\": \"get_leave_balance\",\n                \"description\": \"Fetch remaining leave days.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\"name\": {\"type\": \"string\"}},\n                    \"required\": [\"name\"]\n                }\n            },\n            {\n                \"name\": \"get_product_info\",\n                \"description\": \"Get price and stock of a product.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\"product\": {\"type\": \"string\"}},\n                    \"required\": [\"product\"]\n                }\n            }\n        ]\n    }\n]\n\n# ---- 2. Python Implementations ----\n\ndef get_employee_details(name: str):\n    db = {\n        \"Unnati\": {\"role\": \"Frontend Developer\", \"experience\": \"2 years\"},\n        \"Priyanka\": {\"role\": \"Team Lead\", \"experience\": \"5 years\"},\n        \"Bhoomi\": {\"role\": \"Backend Developer\", \"experience\": \"3 years\"}\n    }\n    return db.get(name, {\"error\": \"Employee not found\"})\n\n\ndef get_salary_details(name: str):\n    salary = {\n        \"Unnati\": {\"basic\": 35000, \"hra\": 15000, \"bonus\": 5000},\n        \"Priyanka\": {\"basic\": 60000, \"hra\": 20000, \"bonus\": 10000}\n    }\n    return salary.get(name, {\"error\": \"Salary record not found\"})\n\n\ndef get_leave_balance(name: str):\n    leaves = {\n        \"Unnati\": {\"remaining_leaves\": 12},\n        \"Priyanka\": {\"remaining_leaves\": 5},\n        \"Bhoomi\": {\"remaining_leaves\": 9}\n    }\n    return leaves.get(name, {\"error\": \"Leave info not found\"})\n\n\ndef get_product_info(product: str):\n    products = {\n        \"Laptop\": {\"price\": 55000, \"stock\": 34},\n        \"Mouse\": {\"price\": 799, \"stock\": 120},\n        \"Keyboard\": {\"price\": 1499, \"stock\": 75}\n    }\n    return products.get(product, {\"error\": \"Product not found\"})\n\n\n# ---- 3. Universal Tool Executor ----\n\ndef execute_tool(name, args):\n    if name == \"get_employee_details\":\n        return get_employee_details(**args)\n    if name == \"get_salary_details\":\n        return get_salary_details(**args)\n    if name == \"get_leave_balance\":\n        return get_leave_balance(**args)\n    if name == \"get_product_info\":\n        return get_product_info(**args)\n\n    return {\"error\": f\"Unknown tool {name}\"}\n\n\n# ---- 4. Initialize Model ----\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.5-flash\",\n    tools=tools\n)\n\n\n# ---- 5. Multi-Tool Agent Loop ----\ndef agent(query):\n    print(\"\\nUSER:\", query)\n\n    # Step A ‚Äî Ask the model\n    response = model.generate_content(query)\n    part = response.candidates[0].content.parts[0]\n\n    # Step B ‚Äî If tool call is requested\n    if hasattr(part, \"function_call\") and part.function_call:\n        call = part.function_call\n        args = dict(call.args)\n\n        print(\"\\nüîß Tool needed:\", call.name)\n        print(\"Arguments:\", args)\n\n        # Step C ‚Äî Execute appropriate Python function\n        tool_result = execute_tool(call.name, args)\n        print(\"üõ† Tool Output:\", tool_result)\n\n        # Step D ‚Äî Send result back to Gemini\n        final = model.generate_content(\n            [\n                {\"role\": \"user\", \"parts\": query},\n                {\n                    \"role\": \"tool\",\n                    \"parts\": [\n                        {\n                            \"function_response\": {\n                                \"name\": call.name,\n                                \"response\": tool_result\n                            }\n                        }\n                    ]\n                }\n            ]\n        )\n\n        print(\"\\nü§ñ AGENT:\")\n        print(final.text)\n        return final.text\n\n    else:\n        # No tool needed ‚Üí Normal text response\n        print(\"\\nü§ñ AGENT:\")\n        print(part.text)\n        return part.text\n\n\n# ---- 6. Test ----\nagent(\"What is the salary of Priyanka?\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:12:12.009386Z","iopub.execute_input":"2025-12-01T06:12:12.010061Z","iopub.status.idle":"2025-12-01T06:12:13.375205Z","shell.execute_reply.started":"2025-12-01T06:12:12.010032Z","shell.execute_reply":"2025-12-01T06:12:13.374387Z"}},"outputs":[{"name":"stdout","text":"\nUSER: What is the salary of Priyanka?\n\nüîß Tool needed: get_salary_details\nArguments: {'name': 'Priyanka'}\nüõ† Tool Output: {'basic': 60000, 'hra': 20000, 'bonus': 10000}\n\nü§ñ AGENT:\nPriyanka's salary is 90K (60K Basic + 10K Bonus + 20K HRA).\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"Priyanka's salary is 90K (60K Basic + 10K Bonus + 20K HRA).\""},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# STEP 7 ‚Äî Add multiple enterprise functions / tools\n\n# ---- 1. Define more tools ----\ntools = [\n    {\n        \"function_declarations\": [\n            {\n                \"name\": \"get_employee_details\",\n                \"description\": \"Fetch role and experience of an employee.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"name\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"name\"]\n                }\n            },\n            {\n                \"name\": \"get_employee_salary\",\n                \"description\": \"Return salary of an employee.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"name\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"name\"]\n                }\n            },\n            {\n                \"name\": \"list_all_employees\",\n                \"description\": \"Returns a list of all employees in the company.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {}\n                }\n            }\n        ]\n    }\n]\n\n\n# ---- 2. Define actual Python functions ----\ndef get_employee_details(name: str):\n    employees = {\n        \"Unnati\": {\"role\": \"Frontend Developer\", \"experience\": \"2 years\"},\n        \"Priyanka\": {\"role\": \"Team Lead\", \"experience\": \"5 years\"},\n        \"Bhoomi\": {\"role\": \"Backend Developer\", \"experience\": \"3 years\"},\n    }\n    return employees.get(name, {\"error\": \"Employee not found\"})\n\n\ndef get_employee_salary(name: str):\n    salaries = {\n        \"Unnati\": 65000,\n        \"Priyanka\": 90000,\n        \"Bhoomi\": 70000,\n    }\n    return {\"salary\": salaries.get(name, \"Not available\")}\n\n\ndef list_all_employees():\n    return [\"Unnati\", \"Priyanka\", \"Bhoomi\"]\n\n\n# ---- 3. Reinitialize the agent with new tools ----\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.5-flash\",\n    tools=tools\n)\n\nprint(\"‚úÖ Tools updated successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:14:21.800956Z","iopub.execute_input":"2025-12-01T06:14:21.801312Z","iopub.status.idle":"2025-12-01T06:14:21.811563Z","shell.execute_reply.started":"2025-12-01T06:14:21.801289Z","shell.execute_reply":"2025-12-01T06:14:21.810579Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Tools updated successfully!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# STEP 8 ‚Äî Universal Agent Loop (supports all tools)\n\nimport json\n\n# Map tool names ‚Üí Python functions\ntool_router = {\n    \"get_employee_details\": get_employee_details,\n    \"get_employee_salary\": get_employee_salary,\n    \"list_all_employees\": lambda: list_all_employees()\n}\n\n\ndef agent(query):\n    print(f\"\\nüîµ USER: {query}\")\n\n    # Step 1 ‚Äî Ask Gemini\n    response = model.generate_content(query)\n    part = response.candidates[0].content.parts[0]\n\n    # Step 2 ‚Äî Check if Gemini wants to call a tool\n    if hasattr(part, \"function_call\") and part.function_call:\n        call = part.function_call\n        tool_name = call.name\n        tool_args = dict(call.args)\n\n        print(f\"\\nüß∞ Gemini requested tool: {tool_name}\")\n        print(\"Arguments:\", tool_args)\n\n        # Step 3 ‚Äî Run actual Python function\n        if tool_name in tool_router:\n            if tool_args:\n                result = tool_router[tool_name](**tool_args)\n            else:\n                result = tool_router[tool_name]()  # no args tool\n        else:\n            result = {\"error\": \"Unknown tool\"}\n\n        print(\"\\nüõ† Tool Output:\", result)\n\n        # Step 4 ‚Äî Send result back to Gemini\n        final = model.generate_content(\n            [\n                {\"role\": \"user\", \"parts\": query},\n                {\n                    \"role\": \"tool\",\n                    \"parts\": [\n                        {\n                            \"function_response\": {\n                                \"name\": tool_name,\n                                \"response\": result\n                            }\n                        }\n                    ]\n                }\n            ]\n        )\n\n        print(\"\\nü§ñ AGENT RESPONSE:\")\n        print(final.text)\n\n    else:\n        # If no tool call ‚Äî direct response\n        print(\"\\nü§ñ AGENT RESPONSE:\")\n        print(part.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:14:53.321930Z","iopub.execute_input":"2025-12-01T06:14:53.322693Z","iopub.status.idle":"2025-12-01T06:14:53.331156Z","shell.execute_reply.started":"2025-12-01T06:14:53.322653Z","shell.execute_reply":"2025-12-01T06:14:53.330040Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# STEP 9 ‚Äî Full Conversational Agent\n\nchat_history = []  # stores all messages in this session\n\ndef conversational_agent(user_input):\n    print(f\"\\nüîµ USER: {user_input}\")\n    \n    # Add user input to history\n    chat_history.append({\"role\": \"user\", \"parts\": user_input})\n    \n    # Ask Gemini with full history\n    response = model.generate_content(chat_history)\n    part = response.candidates[0].content.parts[0]\n\n    # Check for tool call\n    if hasattr(part, \"function_call\") and part.function_call:\n        call = part.function_call\n        tool_name = call.name\n        tool_args = dict(call.args)\n\n        print(f\"\\nüß∞ Gemini requested tool: {tool_name}\")\n        print(\"Arguments:\", tool_args)\n\n        # Run Python tool\n        if tool_name in tool_router:\n            if tool_args:\n                result = tool_router[tool_name](**tool_args)\n            else:\n                result = tool_router[tool_name]()\n        else:\n            result = {\"error\": \"Unknown tool\"}\n\n        print(\"\\nüõ† Tool Output:\", result)\n\n        # Add tool result to history\n        chat_history.append({\n            \"role\": \"tool\",\n            \"parts\": [{\"function_response\": {\"name\": tool_name, \"response\": result}}]\n        })\n\n        # Send back to Gemini to generate final response\n        final = model.generate_content(chat_history)\n        chat_history.append({\"role\": \"assistant\", \"parts\": final.text})\n\n        print(\"\\nü§ñ AGENT RESPONSE:\")\n        print(final.text)\n\n    else:\n        # Direct response from Gemini\n        chat_history.append({\"role\": \"assistant\", \"parts\": part.text})\n        print(\"\\nü§ñ AGENT RESPONSE:\")\n        print(part.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:17:19.051938Z","iopub.execute_input":"2025-12-01T06:17:19.052232Z","iopub.status.idle":"2025-12-01T06:17:19.061310Z","shell.execute_reply.started":"2025-12-01T06:17:19.052212Z","shell.execute_reply":"2025-12-01T06:17:19.060179Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import google.generativeai as genai\nimport json\n\n# ---- 0. Initialize Model and Tools ----\nchat_history = []\n\ntools = [\n    {\n        \"function_declarations\": [\n            {\n                \"name\": \"get_employee_details\",\n                \"description\": \"Fetch role, experience, and salary of an employee.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"name\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"name\"]\n                }\n            }\n        ]\n    }\n]\n\n# Employee database function\ndef get_employee_details(name: str):\n    database = {\n        \"Unnati\": {\"role\": \"Frontend Developer\", \"experience\": \"2 years\", \"salary\": \"‚Çπ6 LPA\"},\n        \"Priyanka\": {\"role\": \"Team Lead\", \"experience\": \"5 years\", \"salary\": \"‚Çπ12 LPA\"},\n        \"Bhoomi\": {\"role\": \"Backend Developer\", \"experience\": \"3 years\", \"salary\": \"‚Çπ8 LPA\"},\n    }\n    return database.get(name, {\"error\": \"Employee not found\"})\n\ntool_router = {\n    \"get_employee_details\": get_employee_details\n}\n\n# Initialize Gemini model\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.5-flash\",\n    tools=tools\n)\n\n# ---- Helper to extract employee name and requested field ----\ndef extract_employee_name_and_field(user_input):\n    user_input_lower = user_input.lower()\n    name = None\n    field = \"details\"\n    \n    for emp in [\"Unnati\", \"Priyanka\", \"Bhoomi\"]:\n        if emp.lower() in user_input_lower:\n            name = emp\n            break\n    \n    if \"salary\" in user_input_lower:\n        field = \"salary\"\n    elif \"experience\" in user_input_lower:\n        field = \"experience\"\n    \n    return name, field\n\n# ---- 1. Robust Agent with Fallback and Unknown Handling ----\ndef robust_agent(user_input):\n    print(f\"\\nüîµ USER: {user_input}\")\n    chat_history.append({\"role\": \"user\", \"parts\": [user_input]})\n\n    try:\n        name, field = extract_employee_name_and_field(user_input)\n        if name:\n            result = get_employee_details(name)\n            chat_history.append({\n                \"role\": \"tool\",\n                \"parts\": [{\"function_response\": {\"name\": \"get_employee_details\", \"response\": result}}]\n            })\n\n            if \"error\" in result:\n                final_text = f\"‚ö†Ô∏è {result['error']}\"\n            else:\n                if field == \"details\":\n                    final_text = f\"{name} is a {result['role']} with {result['experience']} of experience, and an annual salary of {result['salary']}.\"\n                else:\n                    final_text = f\"{name}'s {field} is {result.get(field, 'not found')}.\"\n            \n            chat_history.append({\"role\": \"assistant\", \"parts\": [final_text]})\n            print(\"\\nü§ñ AGENT RESPONSE:\")\n            print(final_text)\n        else:\n            fallback_msg = \"‚ö†Ô∏è Sorry, employee not recognized or no valid information found.\"\n            chat_history.append({\"role\": \"assistant\", \"parts\": [fallback_msg]})\n            print(\"\\nü§ñ AGENT RESPONSE:\")\n            print(fallback_msg)\n\n    except Exception as e:\n        fallback_msg = f\"‚ö†Ô∏è Sorry, I couldn't process your request due to: {str(e)}\"\n        chat_history.append({\"role\": \"assistant\", \"parts\": [fallback_msg]})\n        print(\"\\nü§ñ AGENT RESPONSE:\")\n        print(fallback_msg)\n\n\n# ---- 2. Test the updated agent ----\nrobust_agent(\"Get details for employee Unnati\")\nrobust_agent(\"What is the salary of Priyanka?\")\nrobust_agent(\"Tell me the experience of Bhoomi\")\nrobust_agent(\"Get details for employee Unknown\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:33:23.414196Z","iopub.execute_input":"2025-12-01T06:33:23.414528Z","iopub.status.idle":"2025-12-01T06:33:23.430517Z","shell.execute_reply.started":"2025-12-01T06:33:23.414510Z","shell.execute_reply":"2025-12-01T06:33:23.429380Z"}},"outputs":[{"name":"stdout","text":"\nüîµ USER: Get details for employee Unnati\n\nü§ñ AGENT RESPONSE:\nUnnati is a Frontend Developer with 2 years of experience, and an annual salary of ‚Çπ6 LPA.\n\nüîµ USER: What is the salary of Priyanka?\n\nü§ñ AGENT RESPONSE:\nPriyanka's salary is ‚Çπ12 LPA.\n\nüîµ USER: Tell me the experience of Bhoomi\n\nü§ñ AGENT RESPONSE:\nBhoomi's experience is 3 years.\n\nüîµ USER: Get details for employee Unknown\n\nü§ñ AGENT RESPONSE:\n‚ö†Ô∏è Sorry, employee not recognized or no valid information found.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}